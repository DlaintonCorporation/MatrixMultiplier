Descrição do problema:

Nesse trabalho você deve otimizar a Multiplicação de matrizes (sequencial).

Considere que as matrizes A e B de entrada são matrizes quadradas nxn de doubles (https://en.wikipedia.org/wiki/Double-precision_floating-point_format). Isto pode ser implementado usando 2n3 operações em ponto flutuante (n3 somas, n3 multiplicações), como no seguinte pseudocódigo::

  for i = 1 to n
    for j = 1 to n
      for k = 1 to n
        C(i,j) = C(i,j) + A(i,k) * B(k,j)
      end
    end
  end

Instruções

    O trabalho pode ser feito em dupla. Não copie códigos prontos da internet, estamos aqui para aprender.

    O código TEM que estar correto, códigos retornando resultados errados serão anulados. Em um código correto:

 |square_dgemm(n,A,B,0) - A*B| < eps*n*|A|*|B|. 

onde eps := 2-52 = 2.2 * 10-16 (eps= machine epsilon). (Veja o arquivo benchmark.c: Programa para medir o tempo e verificar a correção do algoritmo)

    A submissão deve ser feita em um tar.gz com nome matmult_integrantes_do_grupo.tar.gz através do link disponibilizado no Moodle (ava.cefetmg.br), contendo:

* dgemm-blocked.c o código fonte C que contém a sua implementação da rotina:

  void square_dgemm(int, double*, double*, double*);

descrita no pseudocódigo acima. Veja no arquivo em anexo uma implementação de exemplo.
* Relatorio.nome.pdf, usar latex: \documentclass[a4paper,10pt]{article}), contendo:

      Introdução: Descreva brevemente qual o objetivo do trabalho da equipe
      Metodologia: Explique por extenso quais métodos usou, o que deu errado, o que deu certo, resultados em cada caso.
      Resultados computacionais: Ambiente computacional, planejamento experimental (objetivo do experimento e como vai ser executado: ex. para comparar o desempenho vou medir o tempo de execução com tais valores de N para diferentes métodos), como mudou o desempenho comparado com sua máquina (desktop/laptop), Figuras com gráficos (usando o gnuplot) de tamanho da matriz vs tempo de execução. Discussão de cada resultado. Documente cada experimento que executar ainda que ele não tenha melhorado o tempo de execução e justifique o que aconteceu. Você deverá executar seus testes com matrizes de diferentes tamanhos. Ex.: 400, 1600, 3600, 6400, 10000. Compare o resultado com os valores obtidos compilando com

    -O3 -fstrict-aliasing -std=c99

(Sobre a keyword C99 restrict e pointer-aliasing, veja este artigo.)

      Conclusões

    Seu código usa precisão dupla para representar números reais.Uma referência  comum para a multiplicação de matrizes com componentes reais é a rotina dgemm (double-precision general matrix-matrix multiply) no nível 3 BLAS. Como parte da avaliação iremos comparar a sua implementação com a dgemm otimizada oferecida na biblioteca BLAS (veja o arquivo benchmark.c).

    A nota irá depender do resultado dessa comparação e da qualidade do seu texto.
    Você pode usar o compilador de sua preferência, sem otimizações. No caso do GNU C compiler (gcc), compile usando gcc -O0. Nesse trabalho não usaremos vetorização.
    As  matrizes estão armazenadas coluna a coluna ou seja, Ci,j == C(i,j) == C[(i-1)+(j-1)*n], for i=1:n, onde n é o número de linhas em C (usamos indexação 1 para símbolos matemáticos e notação de índices em MATLAB (entre parêntesis) e indexação baseada em 0 quando usamos a notação de índices C ( A[i,j] ).
    Seu código só pode chamar funções da biblioteca standard C.
    O processador alvo é um Intel Haswell-EP de 6 cores (12 threads) executando a 2.4 GHz, resultando em 8 double-precision (64-bit) flops por pipeline * 6 pipelines * 2.4 GHz = 115.2 Gflops/s. (Intel(R) Xeon(R) CPU E5-2620 v3 @ 2.40GHz, (CPU speed in GHz) x (number of CPU cores) x (CPU instruction per cycle) x (number of CPUs per node).)

    Você pode implementar algum algoritmo com complexidade assintótica menor que O(n^3) (ex. Strassen https://en.wikipedia.org/wiki/Strassen_algorithm) valendo um ponto adicional, mas ele  não será considerado na comparação de desempenho entre algoritmos sequenciais.

    Você precisará uma conta na katrina (200.131.37.129), entre em contato para criar sua conta. O comando ssh:        ssh seulogin@200.131.37.129 -p 2200 funciona somente dentro do CEFET. Para executar comandos nessa máquina desde fora do CEFET, entre em contato. Para dúvidas e discussões, use o Fórum da disciplina.
    Não deixe os testes para o último dia. Coisas misteriosas podem acontecer com o servidor.

Dicas:

    Experimente com vários tamanhos de bloco e vários níveis de cache;
    Melhore seu código de forma incremental;
    Teste desenrolar laços e otimizações de cópia, troque os laços de ordem,  etc..


Guias de uso do gnuplot:
http://www.uft.edu.br/engambiental/prof/catalunha/arquivos/gnuplot/resumo_gnuplot.pdf
http://www.uel.br/projetos/matessencial/superior/pdfs/Gnuplot-Ajuste.pdf
http://www.notasemcfd.com/2010/02/gnuplot-introducao-basica.html

Referências
Goto, K., and van de Geijn, R. A. 2008. Anatomy of High-Performance Matrix Multiplication, ACM Transactions on Mathematical Software 34, 3, Article 12.
(Note: explains the design decisions for the GotoBLAS dgemm implementation, which also apply to your code.)
Chellappa, S., Franchetti, F., and Püschel, M. 2008. How To Write Fast Numerical Code: A Small Introduction, Lecture Notes in Computer Science 5235, 196-259.
(Note: how to write C code for modern compilers and memory hierarchies, so that it runs fast. Recommended reading, especially for newcomers to code optimization.)
Bilmes, et al. The PHiPAC (Portable High Performance ANSI C) Page for BLAS3 Compatible Fast Matrix Matrix Multiply.
(Note: PHiPAC is a code-generating autotuner for matmul that started as a submission for this HW in a previous semester of CS267. Also see ATLAS; both are good examples if you are considering code generation strategies.)
Lam, M. S., Rothberg, E. E, and Wolf, M. E. 1991. The Cache Performance and Optimization of Blocked Algorithms, ASPLOS'91, 63-74. (Note: clearly explains cache blocking, supported by with performance models.)
